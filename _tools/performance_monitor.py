#!/usr/bin/env python3
"""
æ€§èƒ½ç›£æ§å·¥å…·
ç›£æ§ç¶²ç«™æ€§èƒ½æŒ‡æ¨™ï¼ŒåŒ…æ‹¬é é¢å¤§å°ã€åŠ è¼‰æ™‚é–“ç­‰

ä½¿ç”¨æ–¹æ³•ï¼š
python performance_monitor.py --url https://justin2061.github.io/idea-hub
"""

import argparse
import requests
import time
from pathlib import Path
from datetime import datetime
from typing import Dict, List
import json


class PerformanceMonitor:
    def __init__(self, url: str):
        self.url = url
        self.results = {}

    def measure_page_load(self) -> Dict:
        """æ¸¬é‡é é¢åŠ è¼‰æ€§èƒ½"""
        print(f"ğŸ” æ¸¬é‡é é¢åŠ è¼‰æ€§èƒ½: {self.url}")

        try:
            start_time = time.time()
            response = requests.get(self.url, timeout=30)
            end_time = time.time()

            load_time = end_time - start_time
            content_size = len(response.content)
            status_code = response.status_code

            result = {
                'url': self.url,
                'status_code': status_code,
                'load_time': round(load_time, 3),
                'content_size': content_size,
                'content_size_kb': round(content_size / 1024, 2),
                'timestamp': datetime.now().isoformat(),
                'headers': dict(response.headers)
            }

            print(f"  âœ… ç‹€æ…‹ç¢¼: {status_code}")
            print(f"  â±ï¸  åŠ è¼‰æ™‚é–“: {load_time:.3f} ç§’")
            print(f"  ğŸ“¦ å…§å®¹å¤§å°: {content_size} bytes ({content_size/1024:.2f} KB)")

            return result

        except Exception as e:
            print(f"  âŒ æ¸¬é‡å¤±æ•—: {e}")
            return {
                'url': self.url,
                'error': str(e),
                'timestamp': datetime.now().isoformat()
            }

    def analyze_cache_headers(self, headers: Dict) -> Dict:
        """åˆ†æç·©å­˜é ­"""
        cache_info = {
            'cache_control': headers.get('Cache-Control', 'Not set'),
            'etag': headers.get('ETag', 'Not set'),
            'last_modified': headers.get('Last-Modified', 'Not set'),
            'expires': headers.get('Expires', 'Not set'),
            'content_encoding': headers.get('Content-Encoding', 'Not set')
        }

        print("\nğŸ“‹ ç·©å­˜é ­åˆ†æ:")
        for key, value in cache_info.items():
            print(f"  - {key}: {value}")

        return cache_info

    def generate_report(self, output_file: str = None):
        """ç”Ÿæˆæ€§èƒ½å ±å‘Š"""
        result = self.measure_page_load()

        if 'error' not in result:
            cache_analysis = self.analyze_cache_headers(result['headers'])
            result['cache_analysis'] = cache_analysis

        # ä¿å­˜å ±å‘Š
        if output_file:
            output_path = Path(output_file)
            output_path.parent.mkdir(parents=True, exist_ok=True)

            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(result, f, ensure_ascii=False, indent=2)

            print(f"\nğŸ’¾ å ±å‘Šå·²ä¿å­˜: {output_path}")

        return result

    def compare_with_baseline(self, baseline_file: str):
        """èˆ‡åŸºæº–æ€§èƒ½æ¯”è¼ƒ"""
        print("\nğŸ“Š èˆ‡åŸºæº–æ€§èƒ½æ¯”è¼ƒ...")

        baseline_path = Path(baseline_file)
        if not baseline_path.exists():
            print(f"  âš ï¸  åŸºæº–æ–‡ä»¶ä¸å­˜åœ¨: {baseline_file}")
            return

        with open(baseline_path, 'r', encoding='utf-8') as f:
            baseline = json.load(f)

        current = self.measure_page_load()

        if 'error' in baseline or 'error' in current:
            print("  âŒ ç„¡æ³•æ¯”è¼ƒï¼ˆå­˜åœ¨éŒ¯èª¤ï¼‰")
            return

        # æ¯”è¼ƒæŒ‡æ¨™
        load_time_diff = current['load_time'] - baseline['load_time']
        size_diff = current['content_size'] - baseline['content_size']

        print(f"\nâ±ï¸  åŠ è¼‰æ™‚é–“:")
        print(f"  - åŸºæº–: {baseline['load_time']:.3f} ç§’")
        print(f"  - ç•¶å‰: {current['load_time']:.3f} ç§’")
        print(f"  - å·®ç•°: {load_time_diff:+.3f} ç§’ ({load_time_diff/baseline['load_time']*100:+.1f}%)")

        print(f"\nğŸ“¦ å…§å®¹å¤§å°:")
        print(f"  - åŸºæº–: {baseline['content_size_kb']} KB")
        print(f"  - ç•¶å‰: {current['content_size_kb']} KB")
        print(f"  - å·®ç•°: {size_diff/1024:+.2f} KB ({size_diff/baseline['content_size']*100:+.1f}%)")


def main():
    parser = argparse.ArgumentParser(description='æ€§èƒ½ç›£æ§å·¥å…·')
    parser.add_argument('--url', required=True, help='è¦æ¸¬é‡çš„ç¶²ç«™ URL')
    parser.add_argument('--output', help='è¼¸å‡ºå ±å‘Šæ–‡ä»¶è·¯å¾‘')
    parser.add_argument('--baseline', help='åŸºæº–æ€§èƒ½æ–‡ä»¶è·¯å¾‘ï¼ˆç”¨æ–¼æ¯”è¼ƒï¼‰')

    args = parser.parse_args()

    monitor = PerformanceMonitor(args.url)

    if args.baseline:
        monitor.compare_with_baseline(args.baseline)
    else:
        monitor.generate_report(args.output)


if __name__ == '__main__':
    main()
